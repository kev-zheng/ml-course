{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads 6,000+ emails from the Spamassassin Public Corpus\n",
    "and predicts spam emails through a linear SVM classifier\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import os\n",
    "import chardet\n",
    "from collections import defaultdict\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "ansi = {'underline': '\\033[4m', 'bold': '\\033[1m', 'end':'\\033[0m'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processEmail(email, regexes):\n",
    "    \"\"\"Processes email through (pre-processed) regexes and stemming\"\"\"\n",
    "    \n",
    "    email = email.lower()\n",
    "    email = email.replace('\\n', ' ')\n",
    "    \n",
    "    email = regexes['html'].sub(' ', email)\n",
    "    email = regexes['num'].sub('number', email)\n",
    "    email = regexes['url'].sub('httpaddr', email)\n",
    "    email = regexes['email'].sub('emailaddr', email)\n",
    "    email = regexes['dollar'].sub('dollar', email)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    for c in r\"\"\"@$/#%.-^:&*+=[]?!(){},''\">_<;âˆš\"\"\":\n",
    "        email = email.replace(c, ' ')\n",
    "    \n",
    "    email = re.sub('\\s+', ' ', email).strip() # delete extra spaces and strip\n",
    "    email = email.split(' ') # split by spaces\n",
    "    # stem words in email\n",
    "    email = [stem(x) for x in email]\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeVocabulary(datasets_dir, regexes):\n",
    "    \"\"\"Generates a  of the most frequent words in the dataset\"\"\"\n",
    "    \n",
    "    vocab = defaultdict(int) # Keep track of frequency of words\n",
    "    emails = [] # List for easy translation into DataFrame\n",
    "\n",
    "    for dirpath, _, files in os.walk(datasets_dir):\n",
    "        dirname = os.path.basename(os.path.normpath(dirpath))\n",
    "        print('', end='\\r')\n",
    "        for file in files:\n",
    "            print('Training file {} in {}'.format(file.split('.', 1)[0], dirname), end='\\r')\n",
    "            if file == '.DS_Store': continue # mac OS folder\n",
    "            #email_bit = open(os.path.join(dirpath, file), 'rb').read()\n",
    "            #encoding = chardet.detect(email_bit)['encoding']\n",
    "            email = open(os.path.join(dirpath, file), 'r', errors='ignore').read()\n",
    "            email = email.split('\\n\\n', 1)[-1] # Remove header by splitting at first \\n\\n\n",
    "            \n",
    "            # Add words to vocabulary\n",
    "            word_list = processEmail(email, regexes)\n",
    "            for word in word_list:\n",
    "                vocab[word] += 1\n",
    "            # Add email information to emails, but convert word_list to a set for efficiency\n",
    "            emails.append({'contents': email,\n",
    "                           'sets': set(word_list),\n",
    "                           'spam': 'spam' in dirname,\n",
    "                           'category': dirname})\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    vocab = pd.DataFrame([[item, vocab[item]] for item in vocab], columns=['words', 'frequency'])\n",
    "    vocab = df.sort_values(by='frequency', ascending=False)\n",
    "    vocab = df.drop(df[df['frequency'] < 5].index) # Leaves us with around 12580 features\n",
    "    emails = pd.DataFrame(emails, columns=['contents', 'sets', 'spam', 'category'])\n",
    "    return vocab, emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map email contents to indices and vocabulary\n",
    "def emailFeatures(word_set, vocab_list):\n",
    "    \"\"\"List comprehension that maps every word in word_list to its corresponding feature in vocab_list\"\"\"\n",
    "    return [1 if word in word_set else 0 for word in vocab_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomEmail(emails, model):\n",
    "    \"\"\"Selects a random email from emails and predicts it using model\"\"\"\n",
    "    sample = emails.sample()\n",
    "    original_message = sample['contents'].item()\n",
    "    y = sample['spam'].item()\n",
    "    category = sample['category'].item()\n",
    "    pred = model.predict(sample['X'].tolist()).item()\n",
    "\n",
    "    print('{0:.750}...\\n\\nCorrect: {1}\\nPredicted: {2}\\nCategory: {3}'.format(original_message, y, pred, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datasets_dir = os.path.join(cwd, 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regexes = {'html' : re.compile('<[^<>]+>'),\n",
    "           'num' : re.compile('[0-9]+'),\n",
    "           'url' : re.compile(r'(http|https)://[^\\s]*'),\n",
    "           'email' : re.compile('[^\\s]+@[^\\s]+'),\n",
    "           'dollar' : re.compile('[$]+')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file cmds in spam_22mm22\r"
     ]
    }
   ],
   "source": [
    "vocab, emails = makeVocabulary(datasets_dir, regexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number</td>\n",
       "      <td>109802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the</td>\n",
       "      <td>68770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>to</td>\n",
       "      <td>48595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>and</td>\n",
       "      <td>36129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>a</td>\n",
       "      <td>33696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words  frequency\n",
       "2    number     109802\n",
       "27      the      68770\n",
       "111      to      48595\n",
       "78      and      36129\n",
       "105       a      33696"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>sets</th>\n",
       "      <th>spam</th>\n",
       "      <th>category</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>Dear zzzz =2C\\n\\n=3CBODY bgColor=3D#ffccff=3E\\...</td>\n",
       "      <td>{ffnumber, want, disconnect, power, then, comp...</td>\n",
       "      <td>True</td>\n",
       "      <td>spam</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>The structure of the Internet has never\\nbeen ...</td>\n",
       "      <td>{comput, friend, indistinguish, you, see, less...</td>\n",
       "      <td>False</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>mv 00001.d4365609129eef855bd5da583c90552b 0000...</td>\n",
       "      <td>{enumberenumberfanumberdnumberdnumberanumberbn...</td>\n",
       "      <td>False</td>\n",
       "      <td>easy_ham_2</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>&lt;!doctype html public \"-//w3c//dtd html 4.0 tr...</td>\n",
       "      <td>{effect, other, target, mailt, futur, dure, mi...</td>\n",
       "      <td>True</td>\n",
       "      <td>spam_2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>ok i read back, thats not a typo, you mean thr...</td>\n",
       "      <td>{mention, friend, you, get, cdale, kind, see, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               contents  \\\n",
       "4412  Dear zzzz =2C\\n\\n=3CBODY bgColor=3D#ffccff=3E\\...   \n",
       "954   The structure of the Internet has never\\nbeen ...   \n",
       "3951  mv 00001.d4365609129eef855bd5da583c90552b 0000...   \n",
       "4954  <!doctype html public \"-//w3c//dtd html 4.0 tr...   \n",
       "569   ok i read back, thats not a typo, you mean thr...   \n",
       "\n",
       "                                                   sets   spam    category  \\\n",
       "4412  {ffnumber, want, disconnect, power, then, comp...   True        spam   \n",
       "954   {comput, friend, indistinguish, you, see, less...  False    easy_ham   \n",
       "3951  {enumberenumberfanumberdnumberdnumberanumberbn...  False  easy_ham_2   \n",
       "4954  {effect, other, target, mailt, futur, dure, mi...   True      spam_2   \n",
       "569   {mention, friend, you, get, cdale, kind, see, ...  False    easy_ham   \n",
       "\n",
       "                                                      X  \n",
       "4412  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, ...  \n",
       "954   [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, ...  \n",
       "3951  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4954  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...  \n",
       "569   [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, ...  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create features column 'X'\n",
    "vocab_list = vocab['words'].tolist()\n",
    "emails['X'] = emails['sets'].map(lambda x: emailFeatures(x, vocab_list))\n",
    "\n",
    "# Split data into Train and Test 70 - 30\n",
    "emails, emails_test = train_test_split(emails, test_size=0.3, train_size=0.7)\n",
    "\n",
    "# Linear SVM Classifier\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "model.fit(emails['X'].tolist(), emails['spam'].values)\n",
    "\n",
    "pred = model.predict(np.array(emails_test['X'].tolist()))\n",
    "print('Accuracy on Test Set: {0:0.3g}'.format(np.mean(pred == emails_test['spam'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Top predictors of spam * \n",
      "\n",
      "[Word, weight]\n",
      "click - 0.7834592801596509\n",
      "sweeti - 0.49922664489090735\n",
      "sight - 0.47278284595683834\n",
      "shave - 0.4519259615603336\n",
      "supplement - 0.39319310605931257\n",
      "tabl - 0.3892073666294188\n",
      "our - 0.370187236803594\n",
      "freebsd - 0.3528887629129025\n",
      "z - 0.34454862025197125\n",
      "v - 0.33857483753217993\n",
      "exit - 0.3211763694838365\n",
      "deathtospamdeathtospamdeathtospam - 0.32022500235927626\n",
      "basenumb - 0.3096730961328863\n",
      "pleas - 0.2988402617288223\n",
      "remov - 0.29253102607091813\n"
     ]
    }
   ],
   "source": [
    "# Inspect weights\n",
    "\n",
    "weights = model.coef_.flatten()\n",
    "sorted_indices = weights.argsort()[::-1][:15] # reverse sorted arguments\n",
    "\n",
    "top_spam = [[vocab_list[index], weights[index]] for index in sorted_indices]\n",
    "\n",
    "print('\\n * Top predictors of spam * \\n')\n",
    "print('[Word, weight]')\n",
    "for item in top_spam: print('{} - {}'.format(item[0], item[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear fellow eBay user,\n",
      "\n",
      "I listed this CD on eBay a few months ago and here's \n",
      "what happened.  I got an email from Safeharbor saying \n",
      "that all my auctions had been cancelled and that the CD \n",
      "was permanently \"banned\" from being sold on eBay.  From \n",
      "then on, I called it the \"Banned CD\"!\n",
      "\n",
      "So why did eBay ban it?  Maybe they figured you shouldn't \n",
      "have access to this type of information, or maybe they \n",
      "didn't think we could cram all of these programs onto \n",
      "one CD Rom.  I'll let you decide.\n",
      "\n",
      "This CD will teach you things that eBay, Uncle Sam, and \n",
      "others just don't want you to know.  I am not responsible \n",
      "for how you use some of this information and it is \n",
      "provided for educational purposes only.  Here are just a \n",
      "few of the things you will learn ...\n",
      "\n",
      "Correct: True\n",
      "Predicted: True\n",
      "Category: spam_2\n"
     ]
    }
   ],
   "source": [
    "# Select a random email and predict it\n",
    "randomEmail(emails, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
